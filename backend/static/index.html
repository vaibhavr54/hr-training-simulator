<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI-Powered HR Training Simulator with Real-time Feedback</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap" rel="stylesheet">
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <style>
    * { box-sizing: border-box; }
    body { 
      font-family: 'Roboto', sans-serif; 
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      margin: 0;
      padding: 20px; 
      color: #333; 
      min-height: 100vh;
    }
    .main-container {
      max-width: 1400px;
      margin: 0 auto;
      background: #f4f7f9;
      border-radius: 12px;
      padding: 30px;
      box-shadow: 0 10px 40px rgba(0,0,0,0.2);
    }
    h2 { 
      color: #2c3e50; 
      margin-bottom: 30px;
      font-size: 32px;
      text-align: center;
      font-weight: 700;
    }
    h3 { 
      color: #2c3e50;
      font-size: 20px;
      margin-top: 20px;
      margin-bottom: 12px;
      font-weight: 600;
    }
    .container { 
      display: flex;
      gap: 30px;
      flex-wrap: wrap;
    }
    .left-panel, .right-panel { 
      flex: 1;
      min-width: 320px;
    }
    
    #preview { 
      width: 100%;
      max-height: 400px;
      border-radius: 12px;
      border: 3px solid #ddd;
      margin-bottom: 12px;
      background: #000;
      box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    }
    
    button {
      padding: 12px 20px;
      font-size: 16px;
      margin: 6px 4px;
      border: none;
      border-radius: 8px;
      cursor: pointer;
      transition: all 0.3s;
      font-weight: 600;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    button:hover { transform: translateY(-2px); box-shadow: 0 4px 12px rgba(0,0,0,0.2); }
    button:disabled { 
      opacity: 0.5; 
      cursor: not-allowed;
      transform: none;
    }
    
    #startBtn { background: #4CAF50; color: #fff; }
    #startBtn:hover:not(:disabled) { background: #45a049; }
    
    #stopBtn { background: #f44336; color: #fff; }
    #stopBtn:hover:not(:disabled) { background: #e53935; }
    
    #sortBtn { 
      width: 150px;
      background: #3498db;
      color: white;
      font-size: 14px;
      padding: 8px 12px;
    }
    #sortBtn:hover { background: #2980b9; }
    
    .status {
      font-weight: bold;
      margin-top: 10px;
      color: #27ae60;
      text-align: center;
      min-height: 24px;
      font-size: 15px;
    }
    .status.error { color: #e74c3c; }
    .status.processing { color: #f39c12; }
    
    .card {
      background: #fff;
      padding: 16px;
      border-radius: 10px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.08);
      margin-bottom: 16px;
      word-wrap: break-word;
    }
    
    label {
      display: block;
      margin-bottom: 8px;
      font-weight: 500;
      color: #2c3e50;
      font-size: 15px;
    }
    input, select {
      padding: 10px 12px;
      font-size: 16px;
      border-radius: 8px;
      border: 2px solid #ddd;
      width: 100%;
      margin-bottom: 16px;
      transition: border-color 0.3s;
      font-family: 'Roboto', sans-serif;
    }
    input:focus, select:focus {
      outline: none;
      border-color: #667eea;
    }
    
    .meta-row {
      display: flex;
      gap: 12px;
      align-items: flex-end;
      margin-bottom: 16px;
      flex-wrap: wrap;
    }
    .meta-row > * { flex: 1; min-width: 120px; }
    
    #timerDisplay {
      font-size: 28px;
      font-weight: 700;
      color: #c0392b;
      text-align: center;
      padding: 10px;
      background: #fff;
      border-radius: 8px;
      box-shadow: 0 2px 6px rgba(0,0,0,0.1);
    }
    
    .feedback {
      font-style: italic;
      color: #555;
      margin-top: 10px;
      line-height: 1.6;
      white-space: pre-wrap;
    }
    
    .right-panel {
      max-height: 100vh;
      overflow-y: auto;
      padding-right: 10px;
    }
    .right-panel::-webkit-scrollbar { width: 8px; }
    .right-panel::-webkit-scrollbar-track { background: #f1f1f1; border-radius: 10px; }
    .right-panel::-webkit-scrollbar-thumb { background: #888; border-radius: 10px; }
    .right-panel::-webkit-scrollbar-thumb:hover { background: #555; }
    
    .history-card {
      border-left: 6px solid #3498db;
      cursor: pointer;
      margin-bottom: 8px;
      transition: all 0.3s;
    }
    .history-card:hover {
      transform: translateX(5px);
      box-shadow: 0 4px 12px rgba(0,0,0,0.12);
    }
    .selected-history {
      border-left: 6px solid #e67e22;
      background-color: #fdf2e9;
    }
    
    .button-status-container {
      text-align: center;
      margin-top: 12px;
    }
    
    .emotion-indicator {
      display: inline-block;
      padding: 6px 12px;
      border-radius: 6px;
      font-size: 13px;
      margin-left: 8px;
      font-weight: 600;
    }
    .emotion-positive { background: #d4edda; color: #155724; }
    .emotion-warning { background: #fff3cd; color: #856404; }
    .emotion-negative { background: #f8d7da; color: #721c24; }
    
    .spinner {
      border: 4px solid #f3f3f3;
      border-top: 4px solid #3498db;
      border-radius: 50%;
      width: 40px;
      height: 40px;
      animation: spin 1s linear infinite;
      margin: 20px auto;
    }
    @keyframes spin {
      0% { transform: rotate(0deg); }
      100% { transform: rotate(360deg); }
    }
    
    /* Real-time Feedback Box */
    #liveEmotionFeedback {
      background: linear-gradient(135deg, #667eea15 0%, #764ba215 100%);
      border: 2px solid #667eea;
      min-height: 60px;
      display: flex;
      flex-direction: column;
      padding: 12px;
    }
    
    #emotionStatus {
      font-size: 16px;
      font-weight: 600;
      margin-bottom: 8px;
    }
    
    #liveFeedbackList {
      list-style: none;
      padding: 0;
      margin: 0;
    }
    
    #liveFeedbackList li {
      padding: 4px 0;
      font-size: 14px;
      color: #555;
      animation: fadeIn 0.5s ease-in;
    }
    
    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(-10px); }
      to { opacity: 1; transform: translateY(0); }
    }
    
    .session-header {
      display: flex;
      justify-content: space-between;
      cursor: pointer;
      font-weight: 600;
      margin-bottom: 8px;
      padding: 10px;
      background: #ecf0f1;
      border-radius: 6px;
      transition: background 0.3s;
    }
    .session-header:hover {
      background: #d5dbdb;
    }
    
    .session-content {
      display: none;
      padding-left: 12px;
    }
    
    .attempt-item {
      border-top: 1px solid #eee;
      padding-top: 8px;
      margin-top: 8px;
      font-size: 14px;
    }
    
    .view-link {
      font-size: 13px;
      color: #2980b9;
      cursor: pointer;
      text-decoration: underline;
      margin-top: 6px;
      display: inline-block;
    }
    .view-link:hover {
      color: #3498db;
    }
    
    .chart-container {
      position: relative;
      height: 300px;
      margin-bottom: 16px;
    }
    
    @media (max-width: 768px) {
      .main-container { padding: 15px; }
      h2 { font-size: 24px; }
      .container { flex-direction: column; }
      .meta-row { flex-direction: column; }
      .meta-row > * { width: 100%; }
    }
    
    .error-message {
      background: #f8d7da;
      color: #721c24;
      padding: 12px;
      border-radius: 8px;
      margin: 10px 0;
      border-left: 4px solid #f44336;
    }
    
    .success-message {
      background: #d4edda;
      color: #155724;
      padding: 12px;
      border-radius: 8px;
      margin: 10px 0;
      border-left: 4px solid #4CAF50;
    }
  </style>
</head>
<body>
  <div class="main-container">
    <h2>üéØ AI-Powered HR Training Simulator</h2>
    
    <div class="container">
      <div class="left-panel">
        <label>üë§ Candidate Name:
          <input id="candidate" placeholder="Enter your name" autocomplete="name"/>
        </label>
        
        <label>üíº Role:
          <select id="roleSelect">
            <option value="General">General HR Interview</option>
            <option value="Software Engineer">Software Engineer</option>
            <option value="Data Scientist">Data Scientist</option>
            <option value="Product Manager">Product Manager</option>
            <option value="Marketing Manager">Marketing Manager</option>
            <option value="Sales Executive">Sales Executive</option>
            <option value="UX Designer">UX Designer</option>
            <option value="QA Engineer">QA Engineer</option>
            <option value="Business Analyst">Business Analyst</option>
            <option value="HR Specialist">HR Specialist</option>
            <option value="Operations Manager">Operations Manager</option>
            <option value="Finance Analyst">Finance Analyst</option>
            <option value="Content Writer">Content Writer</option>
            <option value="Data Engineer">Data Engineer</option>
            <option value="Project Manager">Project Manager</option>
          </select>
        </label>

        <label>‚ùì Current Question:
          <div id="currentQuestion" class="card">Select a role to fetch your first question</div>
        </label>

        <label>üéôÔ∏è Live Technical Feedback:
          <div id="liveEmotionFeedback" class="card">
            <div id="emotionStatus">Ready to start...</div>
            <ul id="liveFeedbackList"></ul>
          </div>
        </label>

        <label>üé≠ Live Emotion Insights:
          <div id="liveEmotionInsights" class="card" style="background: linear-gradient(135deg, #ffeaa715 0%, #ffcd0015 100%); border: 2px solid #f39c12; min-height: 80px;">
            <div id="emotionInsightStatus" style="font-weight: 600; margin-bottom: 8px;">Waiting to analyze emotions...</div>
            <ul id="emotionInsightList" style="list-style: none; padding: 0; margin: 0;"></ul>
          </div>
        </label>

        <div class="meta-row">
          <div>
            <label>‚è±Ô∏è Time per answer (minutes)</label>
            <input id="timePerAnswer" type="number" min="1" max="10" value="2"/>
          </div>
          <div style="min-width:140px;">
            <label>‚è∞ Timer</label>
            <div id="timerDisplay">00:00</div>
          </div>
        </div>

        <video id="preview" autoplay playsinline muted></video>
        
        <div class="button-status-container">
          <button id="startBtn">üé• Start Recording</button>
          <button id="stopBtn" disabled>‚èπÔ∏è Stop & Upload</button>
          <div id="status" class="status"></div>
        </div>
      </div>

      <div class="right-panel">
        <h3>üìä Feedback & Scores:</h3>
        <div id="scoreBox" class="card">
          <div class="chart-container">
            <canvas id="scoreChart"></canvas>
          </div>
          <div id="feedbackText" class="feedback">Complete an interview to see your scores</div>
        </div>
        
        <h3>üòÉ Emotional Analysis:</h3>
        <div id="emotionBox" class="card">
          <div class="chart-container" style="height: 250px;">
            <canvas id="emotionChart"></canvas>
          </div>
          <div id="emotionFeedback" class="feedback">Emotion analysis will appear here</div>
        </div>
        
        <h3>üìù Transcript:</h3>
        <div id="transcriptBox" class="card">Your answer transcript will appear here after recording</div>
        
        <div style="display:flex; align-items:center; justify-content:space-between; margin-bottom:10px;">
          <h3 style="margin:0;">üìö Past Attempts:</h3>
          <button id="sortBtn">‚¨áÔ∏è Newest first</button>
        </div>
        <div id="history"></div>
      </div>
    </div>
  </div>

<script>
const preview = document.getElementById('preview');
const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');
const status = document.getElementById('status');
const candidate = document.getElementById('candidate');
const transcriptBox = document.getElementById('transcriptBox');
const roleSelect = document.getElementById('roleSelect');
const currentQuestionDiv = document.getElementById('currentQuestion');
const timePerAnswer = document.getElementById('timePerAnswer');
const timerDisplay = document.getElementById('timerDisplay');
const historyContainer = document.getElementById('history');
const sortBtn = document.getElementById('sortBtn');
const emotionStatus = document.getElementById('emotionStatus');
const liveFeedbackList = document.getElementById('liveFeedbackList');

let mediaStream = null;
let recorder = null;
let chunks = [];
let countdownInterval = null;
let remainingSeconds = 0;
let scoreChart = null;
let emotionChart = null;
let lastQuestion = null;
let lastTranscript = null;
let historySortOrder = "newest";
let faceDetectionInterval = null;
let audioAnalysisInterval = null;
let isRecording = false;
let audioContext = null;
let analyser = null;

// Real-time feedback state
let feedbackMessages = {
  volume: null,
  emotion: null,
  positioning: null,
  duration: null
};

// ========== REAL-TIME AUDIO ANALYSIS ==========
function startAudioAnalysis() {
  if (!mediaStream) return;
  
  try {
    audioContext = new (window.AudioContext || window.webkitAudioContext)();
    const source = audioContext.createMediaStreamSource(mediaStream);
    analyser = audioContext.createAnalyser();
    analyser.fftSize = 2048;
    source.connect(analyser);
    
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    
    let silenceCount = 0;
    let speakingCount = 0;
    let wordCount = 0;
    let startTime = Date.now();
    let lastVolumeUpdate = 0;
    
    console.log('üé§ Audio analysis started - monitoring volume and speech duration');
    
    audioAnalysisInterval = setInterval(() => {
      analyser.getByteFrequencyData(dataArray);
      
      const average = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;
      const currentTime = Date.now();
      
      // Volume feedback (check every second, update UI every 3 seconds)
      if (average < 20) {
        silenceCount++;
        speakingCount = 0;
        if (silenceCount > 3 && currentTime - lastVolumeUpdate > 3000) {
          updateFeedback('volume', 'üîä Speak louder - your voice is too quiet');
          lastVolumeUpdate = currentTime;
          console.log('‚ö†Ô∏è Low volume detected:', average.toFixed(1));
        }
      } else if (average < 40) {
        silenceCount = 0;
        speakingCount++;
        if (speakingCount > 2 && currentTime - lastVolumeUpdate > 3000) {
          updateFeedback('volume', 'üí° Volume could be better');
          lastVolumeUpdate = currentTime;
        }
      } else {
        silenceCount = 0;
        speakingCount++;
        updateFeedback('volume', null);
        wordCount++;
      }
      
      // Speech duration feedback (speaking continuously)
      const elapsedSeconds = (currentTime - startTime) / 1000;
      if (speakingCount > 0 && elapsedSeconds > 10) {
        const estimatedWords = wordCount * 2; // Rough estimate
        
        if (estimatedWords > 200 && elapsedSeconds > 60) {
          updateFeedback('duration', '‚ö° Be more concise - you\'ve been speaking for over a minute');
          console.log('‚ö†Ô∏è Long response detected:', elapsedSeconds.toFixed(0), 'seconds');
        } else if (estimatedWords > 120 && elapsedSeconds > 40) {
          updateFeedback('duration', 'üìù Consider wrapping up your answer soon');
        } else if (elapsedSeconds > 90) {
          updateFeedback('duration', '‚è±Ô∏è Very long response - try to be more concise');
        } else {
          updateFeedback('duration', null);
        }
      }
      
    }, 1000);
    
  } catch (error) {
    console.error('Audio analysis setup error:', error);
  }
}

function stopAudioAnalysis() {
  if (audioAnalysisInterval) {
    clearInterval(audioAnalysisInterval);
    audioAnalysisInterval = null;
  }
  if (audioContext) {
    audioContext.close();
    audioContext = null;
  }
}

// ========== REAL-TIME FACE DETECTION ==========
async function startLiveFaceDetection() {
  if (!mediaStream) return;
  
  const video = document.createElement('video');
  video.srcObject = mediaStream;
  await video.play();
  
  const canvas = document.createElement('canvas');
  const ctx = canvas.getContext('2d');
  
  let checkCount = 0;
  
  console.log('üì∑ Face detection started - monitoring positioning and lighting');
  
  faceDetectionInterval = setInterval(() => {
    if (video.readyState === 4) {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      
      if (canvas.width === 0 || canvas.height === 0) return;
      
      ctx.drawImage(video, 0, 0);
      
      try {
        const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        const centerBrightness = calculateCenterBrightness(imageData);
        const edgeBrightness = calculateEdgeBrightness(imageData);
        
        checkCount++;
        
        // Positioning feedback
        if (centerBrightness < 30) {
          updateFeedback('positioning', 'üí° Improve lighting - it\'s too dark');
          emotionStatus.textContent = '‚ö†Ô∏è Low lighting detected';
          emotionStatus.className = 'emotion-negative';
          console.log('‚ö†Ô∏è Low lighting:', centerBrightness.toFixed(1));
        } else if (Math.abs(centerBrightness - edgeBrightness) > 60) {
          updateFeedback('positioning', 'üì∑ Center yourself in the frame');
          emotionStatus.textContent = 'üì∑ Position adjustment needed';
          emotionStatus.className = 'emotion-warning';
          console.log('‚ö†Ô∏è Poor centering detected');
        } else {
          updateFeedback('positioning', null);
          emotionStatus.textContent = '‚úÖ Good positioning';
          emotionStatus.className = 'emotion-positive';
        }
        
        // Eye contact reminder (every 30 seconds)
        if (checkCount % 15 === 0) {
          updateFeedback('emotion', 'üëÅÔ∏è Look at the camera - maintain eye contact');
          console.log('üí° Eye contact reminder sent');
          setTimeout(() => updateFeedback('emotion', null), 4000);
        }
        
      } catch (e) {
        console.error('Face detection error:', e);
      }
    }
  }, 2000);
}
async function startLiveEmotionDetection() {
  if (!mediaStream) return;
  
  const video = document.createElement('video');
  video.srcObject = mediaStream;
  video.setAttribute('playsinline', '');
  video.setAttribute('autoplay', '');
  await video.play();
  
  const canvas = document.createElement('canvas');
  const ctx = canvas.getContext('2d', { willReadFrequently: true });
  
  emotionInsights = [];
  emotionInsightStatus.textContent = 'üîç Analyzing emotions live...';
  emotionInsightStatus.style.color = '#27ae60';
  
  let frameCount = 0;
  
  emotionDetectionInterval = setInterval(() => {
    if (video.readyState === 4 && isRecording) {
      canvas.width = video.videoWidth || 640;
      canvas.height = video.videoHeight || 480;
      
      if (canvas.width === 0 || canvas.height === 0) return;
      
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      
      try {
        frameCount++;
        const elapsedSeconds = Math.floor((Date.now() - recordingStartTime) / 1000);
        
        // Analyze facial features and brightness patterns for emotion cues
        const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        const emotionCue = analyzeEmotionFromFrame(imageData, elapsedSeconds);
        
        if (emotionCue) {
          addEmotionInsight(emotionCue);
        }
        
      } catch (e) {
        console.error('Live emotion detection error:', e);
      }
    }
  }, 3000); // Check every 3 seconds
}

function analyzeEmotionFromFrame(imageData, timestamp, frameCount) {
  // Analyze brightness, contrast, and movement patterns as emotion indicators
  const data = imageData.data;
  const width = imageData.width;
  const height = imageData.height;
  
  // Sample center region (where face typically is)
  const centerX = Math.floor(width / 2);
  const centerY = Math.floor(height / 2);
  const sampleSize = Math.min(100, Math.floor(width / 4));
  
  let totalBrightness = 0;
  let totalContrast = 0;
  let samples = 0;
  let prevBrightness = null;
  let edgeBrightness = 0;
  let edgeSamples = 0;
  
  // Center brightness
  for (let x = centerX - sampleSize; x < centerX + sampleSize; x += 4) {
    for (let y = centerY - sampleSize; y < centerY + sampleSize; y += 4) {
      if (x >= 0 && x < width && y >= 0 && y < height) {
        const idx = (y * width + x) * 4;
        const brightness = (data[idx] + data[idx + 1] + data[idx + 2]) / 3;
        
        totalBrightness += brightness;
        
        if (prevBrightness !== null) {
          totalContrast += Math.abs(brightness - prevBrightness);
        }
        prevBrightness = brightness;
        samples++;
      }
    }
  }
  
  // Edge brightness (for positioning)
  for (let x = 0; x < width; x += 10) {
    const idx = (10 * width + x) * 4;
    edgeBrightness += (data[idx] + data[idx + 1] + data[idx + 2]) / 3;
    edgeSamples++;
  }
  
  if (samples === 0) return null;
  
  const avgBrightness = totalBrightness / samples;
  const avgContrast = totalContrast / samples;
  const avgEdgeBrightness = edgeSamples > 0 ? edgeBrightness / edgeSamples : avgBrightness;
  
  // Varied emotion feedback based on multiple factors
  const feedbackOptions = [];
  
  // Low energy detection (low contrast)
  if (avgContrast < 15 && timestamp > 5) {
    feedbackOptions.push({
      timestamp,
      message: `Show more facial expressions and energy`,
      type: 'low_energy',
      priority: 3
    });
  }
  
  // Very low brightness - poor lighting or looking down
  if (avgBrightness < 50 && timestamp > 3) {
    feedbackOptions.push({
      timestamp,
      message: `Look directly at the camera`,
      type: 'eye_contact',
      priority: 2
    });
  }
  
  // Moderate brightness with low contrast - monotone delivery
  if (avgBrightness > 60 && avgBrightness < 120 && avgContrast < 18 && timestamp > 8) {
    feedbackOptions.push({
      timestamp,
      message: `Vary your tone and show enthusiasm`,
      type: 'monotone',
      priority: 2
    });
  }
  
  // High contrast - good expressiveness (positive)
  if (avgContrast > 28 && timestamp > 4 && frameCount % 10 === 0) {
    feedbackOptions.push({
      timestamp,
      message: `Great energy! Keep it up`,
      type: 'positive',
      priority: 1
    });
  }
  
  // Poor centering
  if (Math.abs(avgBrightness - avgEdgeBrightness) > 50 && timestamp > 6) {
    feedbackOptions.push({
      timestamp,
      message: `Adjust your position to center yourself`,
      type: 'positioning',
      priority: 3
    });
  }
  
  // Confidence reminders at specific intervals with variety
  if (timestamp % 15 === 0 && timestamp > 0) {
    const confidenceMessages = [
      `At ${timestamp}s: Remember to smile naturally`,
      `At ${timestamp}s: Maintain confident posture`,
      `At ${timestamp}s: Project confidence through your voice`,
      `At ${timestamp}s: Keep steady eye contact`
    ];
    const randomMsg = confidenceMessages[Math.floor(Math.random() * confidenceMessages.length)];
    feedbackOptions.push({
      timestamp,
      message: randomMsg,
      type: 'reminder',
      priority: 4
    });
  }
  
  // Engagement check
  if (avgContrast > 20 && avgBrightness > 80 && timestamp > 10 && frameCount % 15 === 0) {
    feedbackOptions.push({
      timestamp,
      message: `At ${timestamp}s: Excellent engagement with the question`,
      type: 'positive',
      priority: 1
    });
  }
  
  // Return highest priority feedback
  if (feedbackOptions.length > 0) {
    feedbackOptions.sort((a, b) => a.priority - b.priority);
    return feedbackOptions[0];
  }
  
  return null;
}

function addEmotionInsight(insight) {
  if (!insight) return;
  
  // Stricter duplicate detection - check message similarity, not just type
  const isDuplicate = emotionInsights.some(existing => {
    const timeDiff = Math.abs(existing.timestamp - insight.timestamp);
    const sameType = existing.type === insight.type;
    const similarMessage = existing.message.includes(insight.message.split(':')[1]?.trim().substring(0, 20));
    
    // Duplicate if same type within 15 seconds OR similar message within 20 seconds
    return (sameType && timeDiff < 15) || (similarMessage && timeDiff < 20);
  });
  
  if (isDuplicate) return;
  
  // Skip low priority feedback if we already have enough insights
  if (insight.priority >= 4 && emotionInsights.length > 2) return;
  
  // Don't add if last insight was less than 3 seconds ago
  if (emotionInsights.length > 0) {
    const lastInsight = emotionInsights[emotionInsights.length - 1];
    if (insight.timestamp - lastInsight.timestamp < 3) return;
  }
  
  emotionInsights.push(insight);
  
  // Add to UI
  const li = document.createElement('li');
  li.textContent = insight.message;
  li.style.padding = '4px 0';
  li.style.fontSize = '14px';
  li.style.animation = 'fadeIn 0.5s ease-in';
  
  // Color coding based on feedback type
  if (insight.type === 'positive' || insight.type === 'happy' || insight.type === 'good_posture' || insight.type === 'surprised') {
    li.style.color = '#27ae60';
    li.style.fontWeight = '600';
  } else if (insight.type === 'sad' || insight.type === 'fearful' || insight.type === 'angry' || 
             insight.type === 'looking_down' || insight.type === 'head_tilt' || insight.type === 'poor_posture') {
    li.style.color = '#e67e22';
  } else if (insight.type === 'no_face' || insight.type === 'positioning') {
    li.style.color = '#e74c3c';
  } else {
    li.style.color = '#555';
  }
  
  emotionInsightList.appendChild(li);
  
  // Keep only last 6 insights visible
  while (emotionInsightList.children.length > 6) {
    emotionInsightList.removeChild(emotionInsightList.firstChild);
  }
}

function stopLiveEmotionDetection() {
  if (emotionDetectionInterval) {
    clearInterval(emotionDetectionInterval);
    emotionDetectionInterval = null;
  }
  postureHistory = [];
  lastDetectedEmotion = null;
  emotionInsightStatus.textContent = 'Analysis complete';
  emotionInsightStatus.style.color = '#3498db';
}

function clearEmotionInsights() {
  emotionInsights = [];
  postureHistory = [];
  lastDetectedEmotion = null;
  emotionInsightList.innerHTML = '';
  emotionInsightStatus.textContent = 'Waiting to analyze emotions...';
  emotionInsightStatus.style.color = '#7f8c8d';
}

function calculateCenterBrightness(imageData) {
  const data = imageData.data;
  const centerX = Math.floor(imageData.width / 2);
  const centerY = Math.floor(imageData.height / 2);
  const sampleSize = 50;
  let totalBrightness = 0;
  let samples = 0;
  
  for (let x = Math.max(0, centerX - sampleSize); x < Math.min(imageData.width, centerX + sampleSize); x++) {
    for (let y = Math.max(0, centerY - sampleSize); y < Math.min(imageData.height, centerY + sampleSize); y++) {
      const idx = (y * imageData.width + x) * 4;
      const brightness = (data[idx] + data[idx + 1] + data[idx + 2]) / 3;
      totalBrightness += brightness;
      samples++;
    }
  }
  
  return samples > 0 ? totalBrightness / samples : 0;
}

function calculateEdgeBrightness(imageData) {
  const data = imageData.data;
  const width = imageData.width;
  const height = imageData.height;
  let totalBrightness = 0;
  let samples = 0;
  const edgeSize = 20;
  
  for (let x = 0; x < width; x++) {
    for (let y = 0; y < edgeSize; y++) {
      const idx = (y * width + x) * 4;
      const brightness = (data[idx] + data[idx + 1] + data[idx + 2]) / 3;
      totalBrightness += brightness;
      samples++;
    }
  }
  
  return samples > 0 ? totalBrightness / samples : 0;
}

function stopLiveFaceDetection() {
  if (faceDetectionInterval) {
    clearInterval(faceDetectionInterval);
    faceDetectionInterval = null;
  }
}

// ========== UPDATE FEEDBACK UI ==========
function updateFeedback(type, message) {
  feedbackMessages[type] = message;
  
  // Clear and rebuild feedback list
  liveFeedbackList.innerHTML = '';
  
  Object.values(feedbackMessages).forEach(msg => {
    if (msg) {
      const li = document.createElement('li');
      li.textContent = msg;
      liveFeedbackList.appendChild(li);
    }
  });
}

function clearAllFeedback() {
  feedbackMessages = {
    volume: null,
    emotion: null,
    positioning: null,
    duration: null
  };
  liveFeedbackList.innerHTML = '';
  emotionStatus.textContent = 'Ready to start...';
  emotionStatus.className = '';
  clearEmotionInsights();
}

// ========== DYNAMIC QUESTION FETCH ==========
async function fetchNextQuestion(lastAnswer = null) {
  const form = new FormData();
  form.append("candidate", candidate.value || "unknown");
  form.append("role", roleSelect.value || "General");
  if (lastAnswer) form.append("last_answer", lastAnswer);
  
  currentQuestionDiv.innerHTML = '<div class="spinner"></div>';
  
  try {
    const res = await fetch("/next-question", {
      method: "POST",
      body: form
    });
    
    if (!res.ok) throw new Error('Failed to fetch question');
    
    const data = await res.json();
    lastQuestion = data.question;
    currentQuestionDiv.textContent = lastQuestion;
  } catch (err) {
    console.error('Question fetch error:', err);
    currentQuestionDiv.textContent = "[Error fetching question. Please try again.]";
    currentQuestionDiv.className = 'card error-message';
    setTimeout(() => {
      currentQuestionDiv.className = 'card';
    }, 3000);
  }
}

// ========== MEDIA INITIALIZATION ==========
async function initMedia() {
  try {
    mediaStream = await navigator.mediaDevices.getUserMedia({
      video: {
        width: { ideal: 1280 },
        height: { ideal: 720 },
        facingMode: 'user'
      },
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
      }
    });
    
    preview.srcObject = mediaStream;
    status.textContent = '‚úÖ Camera & microphone ready';
    status.className = 'status';
  } catch (err) {
    console.error('Media access error:', err);
    status.textContent = '‚ùå Cannot access camera/mic: ' + err.message;
    status.className = 'status error';
    alert("Please allow camera and microphone access to use this application.");
  }
}

// ========== TIMER ==========
function updateTimerDisplay(sec) {
  const mm = String(Math.floor(sec / 60)).padStart(2, "0");
  const ss = String(sec % 60).padStart(2, "0");
  timerDisplay.textContent = `${mm}:${ss}`;
  
  if (sec <= 30 && sec > 0) {
    timerDisplay.style.color = '#e67e22';
  } else if (sec <= 10) {
    timerDisplay.style.color = '#c0392b';
  } else {
    timerDisplay.style.color = '#27ae60';
  }
}

// ========== RENDER SCORES ==========
function renderScores(score) {
  if (!score) {
    document.getElementById("feedbackText").innerHTML = '<em>No scores available</em>';
    return;
  }
  
  if (typeof score === "string") {
    try {
      score = JSON.parse(score);
    } catch (e) {
      console.error('Score parsing error:', e);
      return;
    }
  }
  
  const labels = ["Communication", "Confidence", "Structure", "Soft Skills"];
  const values = [
    score.communication ?? 0,
    score.confidence ?? 0,
    score.structure ?? 0,
    score.soft_skills ?? 0
  ];
  
  if (scoreChart) scoreChart.destroy();
  
  const ctx = document.getElementById("scoreChart").getContext("2d");
  scoreChart = new Chart(ctx, {
    type: "bar",
    data: {
      labels,
      datasets: [{
        label: "Score (0-100)",
        data: values,
        backgroundColor: [
          "#3498db",
          "#2ecc71",
          "#f39c12",
          "#9b59b6"
        ],
        borderWidth: 2,
        borderColor: "#fff"
      }]
    },
    options: {
      responsive: true,
      maintainAspectRatio: false,
      scales: {
        y: {
          beginAtZero: true,
          max: 100,
          ticks: {
            font: { size: 12 }
          }
        },
        x: {
          ticks: {
            font: { size: 12 }
          }
        }
      },
      plugins: {
        legend: {
          display: false
        },
        tooltip: {
          backgroundColor: 'rgba(0,0,0,0.8)',
          padding: 12,
          titleFont: { size: 14 },
          bodyFont: { size: 13 }
        }
      }
    }
  });

  document.getElementById("feedbackText").innerHTML = 
    `<strong>üí¨ Feedback:</strong><br>${score.feedback ?? "No feedback available"}`;
}

// ========== RENDER EMOTIONS (WITHOUT FACE SCORE) ==========
function renderEmotions(emotionData) {
  if (!emotionData || !emotionData.emotion_distribution) {
    document.getElementById("emotionFeedback").innerHTML = 
      '<em>No emotion data available for this recording</em>';
    return;
  }
  
  const labels = Object.keys(emotionData.emotion_distribution);
  const values = Object.values(emotionData.emotion_distribution);
  
  const colors = {
    'happy': '#2ecc71',
    'sad': '#3498db',
    'angry': '#e74c3c',
    'fear': '#9b59b6',
    'disgust': '#95a5a6',
    'surprise': '#f39c12',
    'neutral': '#34495e'
  };
  
  const backgroundColors = labels.map(label => colors[label] || '#95a5a6');
  
  if (emotionChart) emotionChart.destroy();
  
  const ctx = document.getElementById("emotionChart").getContext("2d");
  emotionChart = new Chart(ctx, {
    type: "doughnut",
    data: {
      labels: labels.map(l => l.charAt(0).toUpperCase() + l.slice(1)),
      datasets: [{
        data: values,
        backgroundColor: backgroundColors,
        borderWidth: 2,
        borderColor: '#fff'
      }]
    },
    options: {
      responsive: true,
      maintainAspectRatio: false,
      plugins: {
        legend: {
          position: 'right',
          labels: {
            font: { size: 12 },
            padding: 10
          }
        },
        title: {
          display: true,
          text: `Dominant: ${(emotionData.dominant_emotion || 'neutral').toUpperCase()}`,
          font: { size: 16, weight: 'bold' },
          color: '#2c3e50'
        },
        tooltip: {
          backgroundColor: 'rgba(0,0,0,0.8)',
          padding: 12
        }
      }
    }
  });
  
  // Only show confidence score, no post-recording feedback messages
  let feedbackHtml = '<strong>Emotion Distribution Summary</strong><br>';
  
  if (emotionData.confidence_score !== undefined) {
    feedbackHtml += `<strong>Confidence Score:</strong> ${emotionData.confidence_score}/100`;
  } else {
    feedbackHtml += 'Confidence score not available';
  }
  
  document.getElementById("emotionFeedback").innerHTML = feedbackHtml;
}

// ========== LOAD HISTORY ==========
async function loadHistory() {
  if (!candidate.value || candidate.value.trim() === '') return;
  
  try {
    const res = await fetch(`/history/${encodeURIComponent(candidate.value.trim())}`);
    if (!res.ok) throw new Error('Failed to load history');
    
    const data = await res.json();
    historyContainer.innerHTML = "";

    if (!data.history || data.history.length === 0) {
      historyContainer.innerHTML = '<div class="card"><em>No past attempts found. Start your first interview!</em></div>';
      return;
    }

    const attempts = data.history.sort((a, b) => {
      return historySortOrder === "newest"
        ? new Date(b.timestamp) - new Date(a.timestamp)
        : new Date(a.timestamp) - new Date(b.timestamp);
    });

    const sessionsMap = {};
    attempts.forEach((item) => {
      const date = new Date(item.timestamp);
      const sessionKey = `${item.role || "General"}|${date.toDateString()}`;
      if (!sessionsMap[sessionKey]) sessionsMap[sessionKey] = [];
      sessionsMap[sessionKey].push(item);
    });

    Object.keys(sessionsMap).forEach((key) => {
      const sessionAttempts = sessionsMap[key];
      const [role, dateStr] = key.split("|");

      const sessionDiv = document.createElement("div");
      sessionDiv.className = "card";
      sessionDiv.style.marginBottom = "12px";
      sessionDiv.style.padding = "12px";

      const header = document.createElement("div");
      header.className = "session-header";
      header.innerHTML = `
        <span>üìÖ ${dateStr} - ${role}</span>
        <span style="font-size:13px;color:#7f8c8d;">${sessionAttempts.length} attempt(s)</span>
      `;

      const sessionContent = document.createElement("div");
      sessionContent.className = "session-content";

      sessionAttempts.forEach((item, index) => {
        const attemptDiv = document.createElement("div");
        attemptDiv.className = "attempt-item";
        
        let emotionIndicator = '';
        if (item.emotion_data && item.emotion_data.dominant_emotion) {
          const emotion = item.emotion_data.dominant_emotion;
          const emotionClass = ['happy', 'neutral'].includes(emotion) ? 'emotion-positive' : 
                               ['sad', 'fear', 'disgust'].includes(emotion) ? 'emotion-negative' : 
                               'emotion-warning';
          const emotionIcon = emotion === 'happy' ? 'üòä' : 
                             emotion === 'sad' ? 'üò¢' : 
                             emotion === 'angry' ? 'üò†' : 
                             emotion === 'fear' ? 'üò∞' : 
                             emotion === 'surprise' ? 'üò≤' : 
                             emotion === 'disgust' ? 'ü§¢' : 'üòê';
          emotionIndicator = `<span class="emotion-indicator ${emotionClass}">${emotionIcon} ${emotion}</span>`;
        }
        
        const time = new Date(item.timestamp).toLocaleTimeString();
        const questionPreview = (item.last_question || "No question").substring(0, 80);
        const answerPreview = (item.transcript || "No transcript").substring(0, 100);
        
        attemptDiv.innerHTML = `
          <strong>‚è∞ ${time}</strong> ${emotionIndicator}
          <br><em>Q:</em> ${questionPreview}${questionPreview.length >= 80 ? '...' : ''}
          <br><em>A:</em> ${answerPreview}${answerPreview.length >= 100 ? '...' : ''}
        `;

        const link = document.createElement("div");
        link.className = "view-link";
        link.textContent = "üëÅÔ∏è View full details";
        link.addEventListener("click", () => {
          lastTranscript = item.transcript;
          transcriptBox.textContent = item.transcript || "No transcript available";
          renderScores(item.score);
          if (item.emotion_data) {
            renderEmotions(item.emotion_data);
          }
          
          document.querySelector('.right-panel').scrollTop = 0;
          
          link.textContent = "‚úÖ Loaded!";
          setTimeout(() => {
            link.textContent = "üëÅÔ∏è View full details";
          }, 2000);
        });

        attemptDiv.appendChild(link);
        sessionContent.appendChild(attemptDiv);
      });

      header.addEventListener("click", () => {
        const isHidden = sessionContent.style.display === "none" || sessionContent.style.display === "";
        sessionContent.style.display = isHidden ? "block" : "none";
      });

      sessionDiv.appendChild(header);
      sessionDiv.appendChild(sessionContent);
      historyContainer.appendChild(sessionDiv);
    });
  } catch (err) {
    console.error("History error:", err);
    historyContainer.innerHTML = '<div class="card error-message">Failed to load history. Please try again.</div>';
  }
}

sortBtn.onclick = () => {
  historySortOrder = historySortOrder === "newest" ? "oldest" : "newest";
  sortBtn.textContent = historySortOrder === "newest" ? "‚¨áÔ∏è Newest first" : "‚¨ÜÔ∏è Oldest first";
  loadHistory();
};

// ========== RECORDING ==========
startBtn.addEventListener("click", async () => {
  if (!candidate.value || candidate.value.trim() === '') {
    alert('Please enter your name before starting the interview.');
    candidate.focus();
    return;
  }
  
  if (!lastQuestion || lastQuestion.includes('Error')) {
    alert('Please wait for a question to load before recording.');
    return;
  }
  
  if (!mediaStream) await initMedia();
  if (!mediaStream) {
    alert('Camera/microphone not available. Please check permissions.');
    return;
  }
  
  chunks = [];
  clearAllFeedback();
  
  try {
    const options = { mimeType: "video/webm;codecs=vp8,opus" };
    if (!MediaRecorder.isTypeSupported(options.mimeType)) {
      options.mimeType = "video/webm";
    }
    
    recorder = new MediaRecorder(mediaStream, options);
    
    recorder.ondataavailable = e => {
      if (e.data && e.data.size > 0) {
        chunks.push(e.data);
      }
    };
    
    recorder.onstop = onStop;
    recorder.onerror = (e) => {
      console.error('Recording error:', e);
      status.textContent = '‚ùå Recording error occurred';
      status.className = 'status error';
      resetRecordingState();
    };
    
    recorder.start(1000);
    isRecording = true;
    recordingStartTime = Date.now();
    
    startBtn.disabled = true;
    stopBtn.disabled = false;
    status.textContent = "üî¥ Recording in progress...";
    status.className = 'status';
    
    startLiveFaceDetection();
    startAudioAnalysis();
    startLiveEmotionDetection();
    
    remainingSeconds = (parseInt(timePerAnswer.value) || 2) * 60;
    updateTimerDisplay(remainingSeconds);
    
    clearInterval(countdownInterval);
    countdownInterval = setInterval(() => {
      remainingSeconds--;
      updateTimerDisplay(remainingSeconds);
      
      if (remainingSeconds <= 0) {
        if (recorder && recorder.state !== "inactive") {
          recorder.stop();
        }
        clearInterval(countdownInterval);
        status.textContent = "‚è∞ Time's up ‚Äî processing...";
        status.className = 'status processing';
        stopLiveFaceDetection();
        stopAudioAnalysis();
        stopLiveEmotionDetection();
      }
    }, 1000);
    
  } catch (err) {
    console.error('Start recording error:', err);
    status.textContent = '‚ùå Failed to start recording: ' + err.message;
    status.className = 'status error';
    resetRecordingState();
  }
});

stopBtn.addEventListener("click", () => {
  if (recorder && recorder.state !== "inactive") {
    recorder.stop();
    clearInterval(countdownInterval);
    stopLiveFaceDetection();
    stopAudioAnalysis();
    stopLiveEmotionDetection();
    status.textContent = "‚è∏Ô∏è Stopping...";
    status.className = 'status processing';
  }
});

async function onStop() {
  isRecording = false;
  clearInterval(countdownInterval);
  updateTimerDisplay(0);
  stopLiveFaceDetection();
  stopAudioAnalysis();
  stopLiveEmotionDetection();
  clearAllFeedback();
  
  if (chunks.length === 0) {
    status.textContent = '‚ùå No video data recorded';
    status.className = 'status error';
    resetRecordingState();
    return;
  }
  
  const blob = new Blob(chunks, { type: "video/webm" });
  const fileSizeMB = (blob.size / (1024 * 1024)).toFixed(2);
  
  console.log(`Recording size: ${fileSizeMB}MB`);
  
  if (blob.size < 1000) {
    status.textContent = '‚ùå Recording too short or empty';
    status.className = 'status error';
    resetRecordingState();
    return;
  }
  
  const form = new FormData();
  form.append("file", blob, "interview_response.webm");
  form.append("candidate", candidate.value.trim());
  form.append("role", roleSelect.value || "General");
  form.append("last_question", lastQuestion || "");
  
  status.textContent = `‚è≥ Uploading (${fileSizeMB}MB) and analyzing...`;
  status.className = 'status processing';
  
  try {
    const res = await fetch("/upload-audio", {
      method: "POST",
      body: form
    });
    
    if (!res.ok) {
      throw new Error(`Server error: ${res.status} ${res.statusText}`);
    }
    
    const data = await res.json();
    
    if (data.status === 'error') {
      throw new Error(data.message || 'Upload failed');
    }
    
    status.textContent = "‚úÖ Upload successful!";
    status.className = 'status';
    
    transcriptBox.textContent = data.transcript || "[No transcript available]";
    renderScores(data.score);
    
    if (data.emotions) {
      renderEmotions(data.emotions);
    }
    
    lastTranscript = data.transcript;
    
    await loadHistory();
    await fetchNextQuestion(lastTranscript);
    
    setTimeout(() => {
      status.textContent = "Ready for next question";
    }, 3000);
    
  } catch (err) {
    console.error('Upload error:', err);
    status.textContent = "‚ùå Upload failed: " + err.message;
    status.className = 'status error';
  } finally {
    resetRecordingState();
  }
}

function resetRecordingState() {
  startBtn.disabled = false;
  stopBtn.disabled = true;
  isRecording = false;
  chunks = [];
}

roleSelect.addEventListener("change", () => {
  if (roleSelect.value) {
    fetchNextQuestion();
  }
});

let historyTimeout;
candidate.addEventListener("input", () => {
  clearTimeout(historyTimeout);
  historyTimeout = setTimeout(() => {
    if (candidate.value.trim()) {
      loadHistory();
    } else {
      historyContainer.innerHTML = '<div class="card"><em>Enter your name to view history</em></div>';
    }
  }, 700);
});

window.addEventListener("load", async () => {
  await initMedia();
  await loadFaceApiModels();
  
  try {
    const res = await fetch('/health');
    const health = await res.json();
    console.log('Backend health:', health);
    
    if (!health.whisper_loaded) {
      console.warn('Whisper model not loaded - transcription may fail');
    }
    if (!health.mongodb_connected) {
      console.warn('MongoDB not connected - history will not be saved');
    }
    if (!health.openrouter_configured) {
      console.warn('OpenRouter not configured - AI features limited');
    }
  } catch (err) {
    console.error('Health check failed:', err);
  }
});

window.addEventListener("beforeunload", (e) => {
  if (isRecording) {
    e.preventDefault();
    e.returnValue = "Recording in progress. Are you sure you want to leave?";
    return e.returnValue;
  }
});

window.addEventListener("unload", () => {
  if (mediaStream) {
    mediaStream.getTracks().forEach(track => track.stop());
  }
});

document.addEventListener("keydown", (e) => {
  if ((e.ctrlKey || e.metaKey) && e.key === 'Enter' && !startBtn.disabled) {
    e.preventDefault();
    startBtn.click();
  }
  
  if ((e.ctrlKey || e.metaKey) && e.key === 's' && !stopBtn.disabled) {
    e.preventDefault();
    stopBtn.click();
  }
});

function addTooltip(element, text) {
  element.title = text;
}

addTooltip(startBtn, "Keyboard shortcut: Ctrl+Enter");
addTooltip(stopBtn, "Keyboard shortcut: Ctrl+S");
addTooltip(timePerAnswer, "Set the time limit for each answer");

console.log("%cüéØ HR Training Simulator with Real-Time AI Emotion Detection Loaded!", "color: #667eea; font-size: 16px; font-weight: bold;");
console.log("%cFeatures:", "color: #3498db; font-size: 14px;");
console.log("  ‚úì Face-API.js emotion detection (happy, sad, angry, fearful, surprised, neutral)");
console.log("  ‚úì Real-time posture analysis (head tilt, eye contact, positioning)");
console.log("  ‚úì Audio volume monitoring");
console.log("%cKeyboard Shortcuts:", "color: #3498db; font-size: 14px;");
console.log("  Ctrl+Enter: Start Recording");
console.log("  Ctrl+S: Stop Recording");
</script>
</body>
</html>